{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IU DeepNLP Reading Group Meeting #4\n",
    "## PyTorch Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor as T\n",
    "from torch.autograd import Variable as V\n",
    "from torch.utils import data\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1b- Train NLLM on more data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-10-13 07:26:55--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.184.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.184.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.2’\n",
      "\n",
      "100%[======================================>] 1,115,394   1.44MB/s   in 0.7s   \n",
      "\n",
      "2017-10-13 07:26:56 (1.44 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Downloading sample data for character level RNN\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      " 21989\n",
      " 23498\n",
      "[torch.LongTensor of size 2]\n",
      ", 15961)\n",
      "torch.Size([150, 2]) torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "class ShakespeareDataset(data.Dataset):\n",
    "    def __init__(self, file):\n",
    "        sentence_raw= open(file, 'r').read().split()\n",
    "\n",
    "        self.vocab= set(sentence_raw)\n",
    "        self.vocab_dict= {word:i for i,word in enumerate(self.vocab)}\n",
    "        self.vocab_inv_dict= {i:word for word,i in self.vocab_dict.items()}\n",
    "        \n",
    "        #converting to word ids is easier when feeding to model\n",
    "        sentence= list(map(lambda word:self.vocab_dict[word], sentence_raw))\n",
    "        \n",
    "        self.trigrams= [([sentence[i], sentence[i+1]], sentence[i+2]) for i in range(len(sentence)- 2)]\n",
    "        inputs,targets= zip(*self.trigrams)\n",
    "        self.inputs= torch.from_numpy(np.array(inputs)) #try longtensor?\n",
    "        self.targets= torch.from_numpy(np.array(targets))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trigrams)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "        \n",
    "textdata= ShakespeareDataset('input.txt')\n",
    "print(textdata[10])\n",
    "\n",
    "#Alternate way to use DataLoader using TensorDataset\n",
    "#inp= textdata.inputs\n",
    "#targets= textdata.targets\n",
    "#tensortextdata= torch.utils.data.TensorDataset(inp,targets)\n",
    "#dataloader= torch.utils.data.DataLoader(tensortextdata, batch_size=10, shuffle=True,)\n",
    "dataloader= data.DataLoader(textdata, batch_size=150, shuffle=True,)\n",
    "for sample_batch in dataloader:\n",
    "    x,y= sample_batch\n",
    "    print(x.size(),y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparams\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 50\n",
    "VOCAB_SIZE= len(textdata.vocab)\n",
    "\n",
    "class NLLM(nn.Module):\n",
    "    #Actual Network code. Easy as pie!\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM, context_size=CONTEXT_SIZE):\n",
    "        super(NLLM, self).__init__()\n",
    "        self.emb= nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.linear1=nn.Linear(context_size*embedding_dim,200)\n",
    "        self.linear2=nn.Linear(200,vocab_size)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        #Remember that inputs are minibatched\n",
    "        batch_size= inputs.size()[0]\n",
    "        \n",
    "        h= self.emb(inputs) #Functions like a dictionary. Given inputs, returns corresponding embeddings\n",
    "        #Input: LongTensor (N, W), N = mini-batch, W = number of indices to extract per mini-batch\n",
    "        #Output: (N, W, embedding_dim)\n",
    "        \n",
    "        h= h.view(batch_size,-1) #This reshapes batch*2*10 into batch*20. -1 tells Pytorch to calculate dimensions given constraints\n",
    "        h= F.relu(self.linear1(h))\n",
    "        out= F.relu(self.linear2(h))\n",
    "        logprobs= F.log_softmax(out)\n",
    "        \n",
    "        return logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 2])\n",
      "torch.Size([150, 25670])\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "x,y= None,None\n",
    "for batch in dataloader:\n",
    "    x,y= batch\n",
    "    break\n",
    "    \n",
    "print(x.size())\n",
    "model= NLLM()\n",
    "print(model.forward(V(x)).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-415d888d386a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlog_probs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_dl36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e77fd884dd87>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#This reshapes batch*2*10 into batch*20. -1 tells Pytorch to calculate dimensions given constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlogprobs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_dl36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_dl36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_dl36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_dl36/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_dl36/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py_dl36/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "\n",
    "model= NLLM()\n",
    "#Hooking up the optimizer to the net's parameters. We will use this later to update\n",
    "optimizer= optim.SGD(model.parameters(),lr=0.01) \n",
    "loss_criterion= nn.NLLLoss() #Negative log likelihood\n",
    "\n",
    "losses=[]\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    total_loss=0\n",
    "    for context,targets in dataloader:\n",
    "        #turn data into Autograd variables\n",
    "        context= V(context)\n",
    "        targets= V(targets)\n",
    "        \n",
    "        log_probs= model(context)\n",
    "\n",
    "        loss= loss_criterion(log_probs,targets) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss+= loss.data.numpy() #Autograd var->Tensor->Numpy\n",
    "    losses.append(total_loss)\n",
    "    print(f\"\\rLoss at epoch {i+1}:{total_loss}\",end='')\n",
    "    \n",
    "#Too slow. Let's use the GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/solved-make-sure-that-pytorch-using-gpu-to-compute/4870/2\n",
    "\n",
    "generally speaking, the pattern is:\n",
    "- use .cuda() on any input batches/tensors\n",
    "- use .cuda() on your network module, which will hold your network, like:\n",
    "\n",
    "```\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.layer1 = nn. ...\n",
    "        self.layer2 = nn. ...\n",
    "        ... etc ...\n",
    "```\n",
    "then just do:\n",
    "\n",
    "```\n",
    "model = MyModel()\n",
    "model.cuda()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 10:11112.149080753326"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "\n",
    "model= NLLM()\n",
    "model.cuda()\n",
    "\n",
    "#Hooking up the optimizer to the net's parameters. We will use this later to update\n",
    "#optimizer= optim.SGD(model.parameters(),lr=0.01) \n",
    "optimizer= optim.Adam(model.parameters())\n",
    "loss_criterion= nn.NLLLoss() #Negative log likelihood\n",
    "\n",
    "losses=[]\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    running_loss=0.0\n",
    "    for batch_num,(context,targets) in enumerate(dataloader):\n",
    "        #turn data into Autograd variables\n",
    "        context= V(context.cuda()) #changing inputs to the net into cuda arrays\n",
    "        targets= V(targets.cuda())\n",
    "        \n",
    "        optimizer.zero_grad() #Remember to clear gradients. They accumulate\n",
    "        \n",
    "        \n",
    "        log_probs= model(context)\n",
    "\n",
    "        loss= loss_criterion(log_probs,targets) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "    print(f\"\\rLoss at epoch {i+1}:{running_loss}\",end='')\n",
    "    losses.append(running_loss)\n",
    "    \n",
    "#Too slow. Let's use the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa9af9eb518>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUBlGRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9aff1d080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a poor a poor a poor a poor a poor'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample data using the model\n",
    "\n",
    "def generate(priming_words, model, dataset, length):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        priming words is the first input fed to the language model\n",
    "        model is the language model you're using\n",
    "        length of generated sequence\n",
    "    returns\n",
    "    \"\"\"\n",
    "    context= priming_words.split()\n",
    "    context= list(map(lambda word:dataset.vocab_dict[word], context))\n",
    "    sentence= context[:]\n",
    "    \n",
    "    context= torch.LongTensor(context)\n",
    "    context=context.unsqueeze(0)\n",
    "    \n",
    "    for i in range(length):\n",
    "        #print(context)\n",
    "        inp= V(context.cuda())\n",
    "        log_probs= model(inp)\n",
    "\n",
    "        _,argmax= torch.max(log_probs,1) #get index\n",
    "        next_word= argmax.data[0]\n",
    "        #How to sample from a softmax?\n",
    "        \n",
    "        sentence.append(next_word)\n",
    "        \n",
    "        context[0,0]=context[0,1]\n",
    "        context[0,1]=next_word\n",
    "    \n",
    "    sentence= list(map(lambda word:dataset.vocab_inv_dict[word], sentence))\n",
    "    return \" \".join(sentence)\n",
    "\n",
    "generate(\"You are\", model, textdata, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
